{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bayesian Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient, StreamableHttpConnection\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from chain_reaction.config import APIKeys, ModelBehavior, ModelName\n",
    "from chain_reaction.utils import get_last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Get tools and prompt from MCP sever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Start MCP sever\n",
    "uv run fastmcp run 3-mcp-fundamentals/1-bayesian-tools/server.py:mcp --transport http --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a client connecting to the Bayesian tools MCP server\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"bayesian-tools\": StreamableHttpConnection(url=\"http://localhost:8000/mcp\", transport=\"streamable_http\"),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve tools and system prompt from the Bayesian tools MCP server\n",
    "tools = await client.get_tools(server_name=\"bayesian-tools\")\n",
    "prompt_messages = await client.get_prompt(server_name=\"bayesian-tools\", prompt_name=\"system_prompt\")\n",
    "system_prompt = prompt_messages[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LangChain agent using the retrieved tools and system prompt\n",
    "bayesian_agent = create_agent(\n",
    "    model=init_chat_model(\n",
    "        model=ModelName.CLAUDE_HAIKU,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        api_key=APIKeys().anthropic,\n",
    "        **ModelBehavior.factual().model_dump(),\n",
    "    ),\n",
    "    checkpointer=InMemorySaver(),\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration for a new chat session\n",
    "config = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Turn 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Using `ainvoke` for async call b/c MCP tools are async\n",
    "response = await bayesian_agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I'm trying to figure out the likelihood of rain tomorrow, can you help me out?\")\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(get_last_message(response).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**Example response**\n",
    "\n",
    "---\n",
    "\n",
    "I'd be happy to help you estimate the likelihood of rain tomorrow using Bayesian modeling! This is a great use case for beta-binomial analysis.\n",
    "\n",
    "To get started, I need to understand your prior beliefs about rain in your area. Let me ask you a few questions:\n",
    "\n",
    "1. **What's your prior estimate?** Based on your experience and knowledge of the weather patterns in your location, what probability would you assign to it raining tomorrow? (For example, 0.3 for 30%, 0.5 for 50%, etc.)\n",
    "\n",
    "2. **How confident are you in this estimate?** I can help you express your conviction level using one of these categories:\n",
    "   - **Random**: You have no real basis for your estimate\n",
    "   - **Gut feeling**: You have a vague sense but no strong evidence\n",
    "   - **Educated guess**: You have some experience or data to back it up\n",
    "   - **Reasonably confident**: You have good historical data or knowledge\n",
    "   - **Very confident**: You have extensive data or expertise\n",
    "   - **Bet the farm**: You're extremely certain about this estimate\n",
    "\n",
    "3. **Do you have any recent weather data?** For example, have you checked a weather forecast, or do you have historical data about how many days it rained in your area over a certain period?\n",
    "\n",
    "Once you provide these details, I can help you:\n",
    "- Set up your prior belief as a beta distribution\n",
    "- Update it with any observed data you have\n",
    "- Calculate confidence intervals for your rain probability estimate\n",
    "- Generate sample predictions for tomorrow\n",
    "\n",
    "What are your thoughts on these questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Turn 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await bayesian_agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I believe there's a 1% chance of rain tomorrow, but this is mostly a gut feeling.\")\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(get_last_message(response).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**Example response**\n",
    "\n",
    "---\n",
    "\n",
    "Perfect! Based on your prior belief of 1% chance of rain with a \"gut feeling\" conviction level, your beta distribution parameters are:\n",
    "- **Alpha (α) = 0.07** (representing \"successes\" or rainy days)\n",
    "- **Beta (β) = 6.93** (representing \"failures\" or non-rainy days)\n",
    "\n",
    "This reflects your belief that rain is quite unlikely, but with relatively low conviction since it's just a gut feeling.\n",
    "\n",
    "Now, a few follow-up questions to help refine this further:\n",
    "\n",
    "1. **Do you have any observed data?** For example:\n",
    "   - Have you checked a weather forecast that gives a specific probability?\n",
    "   - Do you have historical data about how many days it rained in your area over the past week, month, or season?\n",
    "\n",
    "2. **Would you like me to:**\n",
    "   - Calculate a confidence interval around your 1% estimate?\n",
    "   - Generate sample predictions to see the range of possible outcomes?\n",
    "   - Help you update your belief if you get new information (like a weather forecast)?\n",
    "\n",
    "What would be most helpful for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Turn 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await bayesian_agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"\"\"I just checked some historical data, and for the last 5 years in January, it's rained on\n",
    "                average 7.4 out of 31 days (37 rainy days out of 155 observed days).\"\"\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(get_last_message(response).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "**Example Response**\n",
    "\n",
    "---\n",
    "\n",
    "Great! Here's what your updated belief looks like after incorporating the historical data:\n",
    "\n",
    "**Updated Beta Distribution:**\n",
    "- **Alpha (α) = 37.07** (rainy days)\n",
    "- **Beta (β) = 124.93** (non-rainy days)\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "1. **Estimated Probability of Rain Tomorrow:** ~23.8% (37.07 / (37.07 + 124.93))\n",
    "   - This is much higher than your initial 1% gut feeling!\n",
    "\n",
    "2. **95% Confidence Interval:** 16.8% to 29.6%\n",
    "   - This means we can be 95% confident that the true probability of rain in January falls somewhere between these bounds.\n",
    "\n",
    "**What This Means:**\n",
    "Your historical data has significantly updated your belief. The data shows that January in your area is actually fairly rainy, with about 1 in 4 days experiencing rain. Your initial gut feeling of 1% was quite optimistic compared to the historical pattern!\n",
    "\n",
    "**Next Steps:**\n",
    "- Would you like me to generate sample predictions to see the range of possible outcomes?\n",
    "- Do you have any additional information (like a weather forecast) that might further refine this estimate?\n",
    "- Would you like to adjust your conviction level in the historical data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Turn 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await bayesian_agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"\"\"There are 27 days left in January; can you simulate what the outcome for rain might be\n",
    "                this month based on everything we've discussed so far?\"\"\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(get_last_message(response).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "**Example Response**\n",
    "\n",
    "---\n",
    "\n",
    "Perfect! I've simulated 10,000 possible outcomes for the remaining 27 days of January based on your updated belief. Here's what the simulation tells us:\n",
    "\n",
    "**Summary of Simulation Results:**\n",
    "\n",
    "**Expected Number of Rainy Days in the Remaining 27 Days:**\n",
    "- **Average probability of rain per day:** ~22.9%\n",
    "- **Expected rainy days:** About 6-7 days out of the remaining 27 days\n",
    "- **Most likely range:** 4-9 rainy days\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Probability Distribution:** The simulation shows that rainy days are fairly likely to occur, with the distribution centered around 6-7 rainy days for the rest of January.\n",
    "\n",
    "2. **Confidence Range:** Based on the simulation, there's a good chance you'll see somewhere between 4-9 rainy days in the remaining 27 days of January.\n",
    "\n",
    "3. **Comparison to Your Initial Belief:** Your original gut feeling of 1% rain was quite optimistic! The historical data shows that January in your area is actually fairly wet, with roughly 1 in 4 days experiencing rain.\n",
    "\n",
    "**What This Means for Tomorrow:**\n",
    "\n",
    "Based on everything we've discussed, **tomorrow has approximately a 23% chance of rain** - significantly higher than your initial 1% estimate, but still more likely to be dry than rainy.\n",
    "\n",
    "Would you like me to:\n",
    "- Calculate the probability for specific scenarios (e.g., \"What's the chance of 5+ rainy days in the remaining month?\")?\n",
    "- Help you update this forecast if you get new information (like a weather forecast)?\n",
    "- Explore how confident you should be in these estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain-reaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
