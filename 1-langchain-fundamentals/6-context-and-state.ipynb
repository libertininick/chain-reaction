{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Context and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import ToolRuntime, tool\n",
    "from pydantic import Field\n",
    "from pydantic.dataclasses import dataclass as pydantic_dataclass\n",
    "\n",
    "from chain_reaction.config import APIKeys, ModelBehavior, ModelName\n",
    "from chain_reaction.utils import get_last_message\n",
    "\n",
    "api_keys = APIKeys()\n",
    "\n",
    "chat_model = init_chat_model(\n",
    "    model=ModelName.CLAUDE_HAIKU,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_keys.anthropic,\n",
    "    **ModelBehavior.deterministic().model_dump(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Context Schema\n",
    "\n",
    "`context_schema` allows you to define additional parameters that get injected into a tool call at runtime, separate from the tool's parameters.\n",
    "\n",
    "These context parameters:\n",
    "\n",
    "- Provide runtime context like user IDs, session data, or configuration\n",
    "- Are automatically injected when the tool is invoked via the `ToolRuntime`\n",
    "  - Are NOT passed to the LLM directly\n",
    "  - Don't appear in the tool's description sent to the LLM\n",
    "  - Allow you to reduce context LLM has to deal with\n",
    "\n",
    "\n",
    "### Why Use `context_schema`?\n",
    "\n",
    "Without `context_schema`, you'd need to either:\n",
    "\n",
    "- Include sensitive data in prompts (security risk)\n",
    "- Use global variables (not thread-safe)\n",
    "- Create tool instances per request (inefficient)\n",
    "\n",
    "Using a `context_schema` and tools, the agent is given the tools to access the appropriate fields per context instance, but it does not have access directly to these fields and it does not see these fields when invoked. They are injected only when the tool is called.\n",
    "\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "- Authentication context: User IDs, permissions, API keys\n",
    "- Environment config: Database connections, feature flags\n",
    "- Session data: Shopping cart, conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a context schema for storing user preferences\n",
    "type TimeOfDay = Literal[\"morning\", \"afternoon\", \"evening\"]\n",
    "\n",
    "\n",
    "@pydantic_dataclass\n",
    "class UserPreferences:\n",
    "    \"\"\"Context schema for user preferences.\n",
    "\n",
    "    Attributes:\n",
    "        favorite_drink_by_time (dict[TimeOfDay, str]): A mapping of time of day to the user's favorite drink.\n",
    "        preferred_language (str): The user's preferred language.\n",
    "    \"\"\"\n",
    "\n",
    "    favorite_drink_by_time: dict[TimeOfDay, str] = Field(\n",
    "        description=\"The user's favorite drink by time of day\",\n",
    "        default_factory=lambda: {\n",
    "            \"morning\": \"coffee\",\n",
    "            \"afternoon\": \"tea\",\n",
    "            \"evening\": \"beer\",\n",
    "        },\n",
    "    )\n",
    "    preferred_language: str = Field(default=\"English\", description=\"The user's preferred language\")\n",
    "\n",
    "\n",
    "# Create tools for accessing user preferences\n",
    "@tool\n",
    "def get_preferred_drink(time_of_day: TimeOfDay, runtime: ToolRuntime[UserPreferences]) -> str:\n",
    "    \"\"\"Get the user's favorite drink by time of day.\"\"\"\n",
    "    return runtime.context.favorite_drink_by_time[time_of_day]\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_preferred_language(runtime: ToolRuntime[UserPreferences]) -> str:\n",
    "    \"\"\"Get the user's preferred language.\"\"\"\n",
    "    return runtime.context.preferred_language\n",
    "\n",
    "\n",
    "# Create the agent with context schema and tools\n",
    "agent = create_agent(\n",
    "    model=chat_model,\n",
    "    system_prompt=\"Please respond to the user's queries based on their preferences.\",\n",
    "    tools=[get_preferred_drink, get_preferred_language],\n",
    "    context_schema=UserPreferences,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default context instance for a user\n",
    "user_context = UserPreferences()\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Good morning! What's my favorite drink?\")]},\n",
    "    context=user_context,\n",
    ")\n",
    "\n",
    "# Extract and print the last message from the agent's response\n",
    "last_message = get_last_message(response)\n",
    "if last_message:\n",
    "    print(\"Agent Response:\", last_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom context instance for a user\n",
    "user_context = UserPreferences(\n",
    "    favorite_drink_by_time={\n",
    "        \"morning\": \"grog\",\n",
    "        \"afternoon\": \"ale\",\n",
    "        \"evening\": \"rum\",\n",
    "    },\n",
    "    preferred_language=\"Pirate English\",\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Arr! The Moon is high! What's me favorite drink?\")]},\n",
    "    context=user_context,\n",
    ")\n",
    "\n",
    "# Extract and print the last message from the agent's response\n",
    "last_message = get_last_message(response)\n",
    "if last_message:\n",
    "    print(\"Agent Response:\", last_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain-reaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
