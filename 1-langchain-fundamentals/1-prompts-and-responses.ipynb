{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Prompts & Responses\n",
    "\n",
    "1. Generate reusable prompt templates\n",
    "2. Parse responses using pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from chain_reaction.config import APIKeys, ModelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "api_keys = APIKeys()\n",
    "\n",
    "\n",
    "# Initialize a chat model with your API key\n",
    "chat_model = ChatAnthropic(\n",
    "    model_name=ModelName.CLAUDE_HAIKU,\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_keys.anthropic,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# 1. Reusable prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple chat prompt template with input variables\n",
    "class PoemInputs(BaseModel):\n",
    "    \"\"\"Poem prompt input variables.\n",
    "\n",
    "    Attributes:\n",
    "        topic (str): The topic of the poem.\n",
    "        funny_or_sad (Literal[\"funny\", \"sad\"]): Whether the poem should be funny or sad. Default is 'funny'.\n",
    "        audience (str): The intended audience for the poem. Default is 'general'.\n",
    "    \"\"\"\n",
    "\n",
    "    topic: str = Field(description=\"The topic of the poem\")\n",
    "    funny_or_sad: Literal[\"funny\", \"sad\"] = Field(\n",
    "        default=\"funny\", description=\"Whether the poem should be funny or sad. Default is 'funny'.\"\n",
    "    )\n",
    "    audience: str = Field(default=\"general\", description=\"The intended audience for the poem.\")\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    template=\"Please write me a short poem about {topic}. This poem should be {funny_or_sad} for {audience}.\",\n",
    ")\n",
    "print(\"Prompt template created successfully.\", \"\\n\", prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get message prompt from the template\n",
    "message_prompt = prompt_template.format_messages(\n",
    "    topic=\"getting dressed in the morning\", funny_or_sad=\"funny\", audience=\"children\"\n",
    ")\n",
    "print(\"Message prompt formatted successfully.\", \"\\n\", message_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a different message prompt from the template using PoemVariables model\n",
    "prompt_variables = PoemInputs(topic=\"eating soup\", funny_or_sad=\"funny\", audience=\"6 year old boy\")\n",
    "message_prompt = prompt_template.format_messages(**prompt_variables.model_dump(mode=\"json\"))\n",
    "print(\"Message prompt formatted successfully.\", \"\\n\", message_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the model and get the response\n",
    "response = chat_model.invoke(message_prompt)\n",
    "\n",
    "print(\"Poem response:\", \"\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to create an invalid message prompt from the template\n",
    "prompt_variables = PoemInputs(topic=\"eating soup\", funny_or_sad=\"warm and cozy\")  # This should raise a validation error\n",
    "message_prompt = prompt_template.format_messages(**prompt_variables.model_dump(mode=\"json\"))\n",
    "print(\"Message prompt formatted successfully.\", \"\\n\", message_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# 2. Enforce structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response model for structured output\n",
    "class PoemOutputs(BaseModel):\n",
    "    \"\"\"Poem response output variables.\n",
    "\n",
    "    Attributes:\n",
    "        title (str): The title of the poem.\n",
    "        content (str): The content of the poem.\n",
    "        voice (str | None): Recommended voice for reading the poem aloud. Optional.\n",
    "    \"\"\"\n",
    "\n",
    "    title: str = Field(description=\"The title of the poem\")\n",
    "    content: str = Field(description=\"The content of the poem.\")\n",
    "    voice: str | None = Field(default=None, description=\"Recommended voice for reading the poem aloud. Optional.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Option A: `PydanticOutputParser` & format instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Create a Pydantic output parser for the response model\n",
    "response_parser = PydanticOutputParser(pydantic_object=PoemOutputs)\n",
    "\n",
    "# Create a prompt template with response format instructions\n",
    "prompt_template_w_format = ChatPromptTemplate.from_template(\n",
    "    template=(\n",
    "        \"Please write me a short poem about {topic}. This poem should be {funny_or_sad} for {audience}.\"\n",
    "        \"\\n\\n{format_instructions}\"\n",
    "    ),\n",
    "    partial_variables={\"format_instructions\": response_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain combining the prompt, chat model, and response parser\n",
    "chain = prompt_template_w_format | chat_model | response_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain with prompt variables\n",
    "prompt_variables = PoemInputs(topic=\"eating soup\", funny_or_sad=\"funny\", audience=\"6 year old boy\")\n",
    "response: PoemOutputs = chain.invoke(prompt_variables.model_dump(mode=\"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structured response\n",
    "print(\"Poem Title:\", response.title)\n",
    "print(\"\\nPoem Content:\", response.content)\n",
    "print(\"\\nRecommended Voice:\", response.voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Option B: New model `with_structured_output`\n",
    "\n",
    " I'd strongly recommend using `.with_structured_output()` instead of `PydanticOutputParser` for Claude models. It's more reliable because it uses Claude's native tool-calling rather than trying to parse JSON from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the chat model to enforce structured output\n",
    "structured_model = chat_model.with_structured_output(PoemOutputs)\n",
    "\n",
    "# Create a chain combining the (original) prompt template and the structured model\n",
    "chain = prompt_template | structured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain with prompt variables\n",
    "response: PoemOutputs = chain.invoke(PoemInputs(topic=\"playing Lego with my sister\").model_dump(mode=\"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structured response\n",
    "print(\"Poem Title:\", response.title)\n",
    "print(\"\\nPoem Content:\", response.content)\n",
    "print(\"\\nRecommended Voice:\", response.voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain-reaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
