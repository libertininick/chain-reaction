{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from chain_reaction.config import APIKeys, ModelBehavior, ModelName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Define a tool\n",
    "\n",
    "- A LangChain tool is a wrapper that makes a function callable by a LLM agent. \n",
    "- It provides the LLM with a description of what the function does, what parameters it expects, and handles the execution when the LLM decides to use it.\n",
    "\n",
    "## How Tools Work\n",
    "\n",
    "When you define a tool, you're creating a structured interface that includes:\n",
    "\n",
    "1. A name and description (so the LLM knows when to use it)\n",
    "    - The tool will be referenced by the function's name\n",
    "    - The function's docstring will serve as the description for the tool.\n",
    "2. Parameter schemas (so the LLM knows what inputs to provide)\n",
    "3. The actual function logic to execute\n",
    "\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- **Write clear, specific descriptions**. The LLM relies entirely on your description to decide when to use the tool. Be explicit about what it does and when it should be used. For example, \"Search for current weather data for a given city\" is better than \"Get weather.\"\n",
    "- **Keep tools focused and single-purpose**. Each tool should do one thing well rather than trying to handle multiple distinct operations. If you need to search products and get product details, create two separate tools rather than one complex tool with modes.\n",
    "- **Define explicit parameter schemas**. Use Pydantic models or clear type hints to specify exactly what parameters your tool accepts. Include descriptions for each parameter to help the LLM understand what values to provide.\n",
    "- **Handle errors gracefully**. Tools should catch exceptions and return meaningful error messages that the LLM can understand and potentially recover from, rather than crashing the entire agent.\n",
    "- **Return structured data when possible**.** Instead of returning raw strings, consider returning dictionaries or Pydantic models that the LLM can more easily parse and reason about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_square_root(number: float) -> float:\n",
    "    \"\"\"Calculates the square root of a given number.\n",
    "\n",
    "    Args:\n",
    "        number (float): The number to calculate the square root of.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the number.\n",
    "    \"\"\"\n",
    "    return number**0.5\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_square(number: float) -> float:\n",
    "    \"\"\"Calculates the square of a given number.\n",
    "\n",
    "    Args:\n",
    "        number (float): The number to calculate the square of.\n",
    "\n",
    "    Returns:\n",
    "        float: The square of the number.\n",
    "    \"\"\"\n",
    "    return number**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Invoke the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the tool with raise an error\n",
    "calculate_square_root(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, use the invoke method\n",
    "calculate_square_root.invoke({\"number\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Create an Agent w/ Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "api_keys = APIKeys()\n",
    "\n",
    "# Initialize a chat model with your API key\n",
    "chat_model = init_chat_model(\n",
    "    model=ModelName.CLAUDE_HAIKU,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_keys.anthropic,\n",
    "    **ModelBehavior.factual().model_dump(),\n",
    ")\n",
    "\n",
    "\n",
    "# Create a response model\n",
    "class CalculationResult(BaseModel):\n",
    "    \"\"\"Response model for calculation results.\"\"\"\n",
    "\n",
    "    result: float = Field(description=\"The result of the calculation.\")\n",
    "\n",
    "\n",
    "# Initialize an agent using the chat model & tools\n",
    "agent = create_agent(\n",
    "    model=chat_model,\n",
    "    tools=[calculate_square_root, calculate_square],\n",
    "    system_prompt=\"\"\"\n",
    "    You're a helpful assistant that can perform mathematical calculations.\n",
    "    Use the provided calculation tools to answer user questions accurately.\n",
    "    \"\"\",\n",
    "    response_format=CalculationResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(input={\"messages\": [HumanMessage(content=\"What's square root of 32,451?\")]})\n",
    "calc_result: CalculationResult = response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = agent.invoke(input={\"messages\": [HumanMessage(content=f\"What's square of {calc_result.result}?\")]})\n",
    "response_2[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain-reaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
