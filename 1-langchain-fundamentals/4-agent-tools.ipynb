{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Any\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from chain_reaction.config import APIKeys, ModelBehavior, ModelName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Define a tool\n",
    "\n",
    "- A LangChain tool is a wrapper that makes a function callable by a LLM agent. \n",
    "- It provides the LLM with a description of what the function does, what parameters it expects, and handles the execution when the LLM decides to use it.\n",
    "\n",
    "## How Tools Work\n",
    "\n",
    "When you define a tool, you're creating a structured interface that includes:\n",
    "\n",
    "1. A name and description (so the LLM knows when to use it)\n",
    "    - The tool will be referenced by the function's name\n",
    "    - The function's docstring will serve as the description for the tool.\n",
    "2. Parameter schemas (so the LLM knows what inputs to provide)\n",
    "3. The actual function logic to execute\n",
    "\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- **Write clear, specific descriptions**. The LLM relies entirely on your description to decide when to use the tool. Be explicit about what it does and when it should be used. For example, \"Search for current weather data for a given city\" is better than \"Get weather.\"\n",
    "- **Keep tools focused and single-purpose**. Each tool should do one thing well rather than trying to handle multiple distinct operations. If you need to search products and get product details, create two separate tools rather than one complex tool with modes.\n",
    "- **Define explicit parameter schemas**. Use Pydantic models or clear type hints to specify exactly what parameters your tool accepts. Include descriptions for each parameter to help the LLM understand what values to provide.\n",
    "- **Handle errors gracefully**. Tools should catch exceptions and return meaningful error messages that the LLM can understand and potentially recover from, rather than crashing the entire agent.\n",
    "- **Return structured data when possible**.** Instead of returning raw strings, consider returning dictionaries or Pydantic models that the LLM can more easily parse and reason about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate_square_root(number: float) -> float:\n",
    "    \"\"\"Calculates the square root of a given number.\n",
    "\n",
    "    Args:\n",
    "        number (float): The number to calculate the square root of.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the number.\n",
    "    \"\"\"\n",
    "    return number**0.5\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_square(number: float) -> float:\n",
    "    \"\"\"Calculates the square of a given number.\n",
    "\n",
    "    Args:\n",
    "        number (float): The number to calculate the square of.\n",
    "\n",
    "    Returns:\n",
    "        float: The square of the number.\n",
    "    \"\"\"\n",
    "    return number**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Invoke the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the tool with raise an error\n",
    "calculate_square_root(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, use the invoke method\n",
    "calculate_square_root.invoke({\"number\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Create an Agent w/ Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "api_keys = APIKeys()\n",
    "\n",
    "# Initialize a chat model with your API key\n",
    "chat_model = init_chat_model(\n",
    "    model=ModelName.CLAUDE_HAIKU,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=api_keys.anthropic,\n",
    "    **ModelBehavior.factual().model_dump(),\n",
    ")\n",
    "\n",
    "\n",
    "# Create a response model\n",
    "class CalculationResult(BaseModel):\n",
    "    \"\"\"Response model for calculation results.\"\"\"\n",
    "\n",
    "    result: float = Field(description=\"The result of the calculation.\")\n",
    "\n",
    "\n",
    "# Initialize an agent using the chat model & tools\n",
    "agent = create_agent(\n",
    "    model=chat_model,\n",
    "    tools=[calculate_square_root, calculate_square],\n",
    "    system_prompt=\"\"\"\n",
    "    You're a helpful assistant that can perform mathematical calculations.\n",
    "    Use the provided calculation tools to answer user questions accurately.\n",
    "    \"\"\",\n",
    "    response_format=CalculationResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(input={\"messages\": [HumanMessage(content=\"What's square root of 32,451?\")]})\n",
    "calc_result: CalculationResult = response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = agent.invoke(input={\"messages\": [HumanMessage(content=f\"What's square of {calc_result.result}?\")]})\n",
    "response_2[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Create web search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tavily client\n",
    "tavily_client = TavilyClient(api_key=api_keys.tavily.get_secret_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool for searching the web using Tavily\n",
    "@tool\n",
    "def search_web(query: str) -> dict[str, Any]:\n",
    "    \"\"\"Performs a web search using Tavily.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: The search results.\n",
    "    \"\"\"\n",
    "    return tavily_client.search(query=query)\n",
    "\n",
    "\n",
    "search_web.invoke({\"query\": \"When will it snow next in Centennial, CO?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a response model\n",
    "class WeatherResult(BaseModel):\n",
    "    \"\"\"Response model for weather results.\"\"\"\n",
    "\n",
    "    forecast_date: datetime.date = Field(description=\"The date of the weather forecast.\")\n",
    "    chance_of_snow: float = Field(description=\"The chance of snow in the specified location.\", ge=0, le=100)\n",
    "    amount_of_snow: float = Field(description=\"The expected amount of snow in inches.\", ge=0)\n",
    "    temperature: float = Field(description=\"The expected temperature in Fahrenheit.\")\n",
    "    snow_start: int | None = Field(\n",
    "        description=\"The hour when snow is expected to start (24-hour format). None if no snow is expected.\",\n",
    "        ge=0,\n",
    "        le=23,\n",
    "    )\n",
    "    snow_end: int | None = Field(\n",
    "        description=\"The hour when snow is expected to end (24-hour format). None if no snow is expected.\", ge=0, le=23\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize an agent using the chat model & tools\n",
    "agent = create_agent(\n",
    "    model=init_chat_model(\n",
    "        model=ModelName.CLAUDE_HAIKU,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        api_key=api_keys.anthropic,\n",
    "        **ModelBehavior.factual().model_dump(),\n",
    "    ),\n",
    "    tools=[search_web],\n",
    "    system_prompt=\"\"\"\n",
    "    You're a helpful assistant that can search the web for weather information.\n",
    "    Use the provided web search tools to answer user questions accurately.\n",
    "    \"\"\",\n",
    "    response_format=WeatherResult,\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"Will centennial, CO have a white Christmas in 2025?\")]}\n",
    ")\n",
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(input={\"messages\": [HumanMessage(content=\"When will it snow next in Centennial, CO?\")]})\n",
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain-reaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
